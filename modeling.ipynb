{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 프로그래밍 시작\n",
    "import torch\n",
    "import pandas as pd\n",
    "import math\n",
    "import collections\n",
    "import tqdm\n",
    "from torch.utils.data import IterableDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe\n",
    "from konlpy.tag import Komoran\n",
    "import datasets\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch version: 2.3.0\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용 GPU: GTX 1650\n",
    "torch.cuda.get_device_name(device = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 전처리\n",
    "def preprocess_dataframe(input_dataframe:pd.DataFrame)->pd.DataFrame:\n",
    "    return_dataframe = input_dataframe.copy(deep=True)\n",
    "    return_dataframe.drop_duplicates(subset=['summary'], inplace=True)\n",
    "    # 한글, 공백만 포함\n",
    "    return_dataframe['korean'] = return_dataframe['summary'].str.replace(pat=r\"[^ㄱ-ㅎㅏ-ㅣ가-힣0-9 ]\", repl=r\"\", regex=True)\n",
    "    # 영어도 포함시킬려면\n",
    "    # return_dataframe['document'] = return_dataframe['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z ]\",\"\")\n",
    "    # 공백만 존재할 경우 na로 대체한다.\n",
    "    return_dataframe['korean'] = return_dataframe['korean'].replace('', np.nan)\n",
    "    # na만 존재하는 행들을 제거한다\n",
    "    return_dataframe = return_dataframe.dropna(how='any')\n",
    "    return return_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40800"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"summarized_df.tsv\", sep='\\t')\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35256</th>\n",
       "      <td>source_data\\speech\\REPORT-speech-09483-00006.json</td>\n",
       "      <td>지배구조 연차보고서에는 사외이사 후보 추천과 사외이사 활동 및 보상에 관한 사항을 ...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29128</th>\n",
       "      <td>source_data\\speech\\REPORT-speech-04350-00001.json</td>\n",
       "      <td>서울경찰청은 여론조사기관에서 실시한 설문조사 결과를 바탕으로 보복 운전 등의 사회적...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>source_data\\briefing\\REPORT-briefing-63316-000...</td>\n",
       "      <td>코로나바이러스감염증19 중앙재난안전대책본부는 영상회의실에서 코로나 블루 극복을 위한...</td>\n",
       "      <td>briefing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>source_data\\briefing\\REPORT-briefing-31343-000...</td>\n",
       "      <td>2021년 소셜벤처 경연대회는 사회문제 해결에 관심 있는 국민이 4개 부문 중 하나...</td>\n",
       "      <td>briefing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>source_data\\edit\\REPORT-edit-20389-00012.json</td>\n",
       "      <td>서양에 못지않게 일찍부터 법률체제를 구축한 중국은 주나라 대에 이르러서는 관리의 문...</td>\n",
       "      <td>edit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>source_data\\briefing\\REPORT-briefing-87674-000...</td>\n",
       "      <td>환경부는 2020 환경 데이터 활용 그린 뉴딜 아이디어 공모전 최종 경연 대회 및 ...</td>\n",
       "      <td>briefing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>source_data\\briefing\\REPORT-briefing-34860-000...</td>\n",
       "      <td>코로나19 상황에서 다양한 형태의 긴급 돌봄을 제공하는 등 가정의 돌봄 부담을 완화...</td>\n",
       "      <td>briefing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30244</th>\n",
       "      <td>source_data\\speech\\REPORT-speech-05450-00005.json</td>\n",
       "      <td>공공재개발을 통해서 사업 장애요인이 해소된다면 실수요자가 원하는 양질의 주택을 공급...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35456</th>\n",
       "      <td>source_data\\speech\\REPORT-speech-09792-00001.json</td>\n",
       "      <td>국립외교원과 유럽연합안보연구원이 공동으로 주최하는 한-EU 동북아 평화협력구상 세미...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7816</th>\n",
       "      <td>source_data\\briefing\\REPORT-briefing-86575-000...</td>\n",
       "      <td>환경부와 지자체는 대기오염물질 모니터링 및 오염원 특성 파악을 위해 11종의 측정망...</td>\n",
       "      <td>briefing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  \\\n",
       "35256  source_data\\speech\\REPORT-speech-09483-00006.json   \n",
       "29128  source_data\\speech\\REPORT-speech-04350-00001.json   \n",
       "4561   source_data\\briefing\\REPORT-briefing-63316-000...   \n",
       "1954   source_data\\briefing\\REPORT-briefing-31343-000...   \n",
       "10206      source_data\\edit\\REPORT-edit-20389-00012.json   \n",
       "...                                                  ...   \n",
       "7977   source_data\\briefing\\REPORT-briefing-87674-000...   \n",
       "2494   source_data\\briefing\\REPORT-briefing-34860-000...   \n",
       "30244  source_data\\speech\\REPORT-speech-05450-00005.json   \n",
       "35456  source_data\\speech\\REPORT-speech-09792-00001.json   \n",
       "7816   source_data\\briefing\\REPORT-briefing-86575-000...   \n",
       "\n",
       "                                                 summary     label  \n",
       "35256  지배구조 연차보고서에는 사외이사 후보 추천과 사외이사 활동 및 보상에 관한 사항을 ...    speech  \n",
       "29128  서울경찰청은 여론조사기관에서 실시한 설문조사 결과를 바탕으로 보복 운전 등의 사회적...    speech  \n",
       "4561   코로나바이러스감염증19 중앙재난안전대책본부는 영상회의실에서 코로나 블루 극복을 위한...  briefing  \n",
       "1954   2021년 소셜벤처 경연대회는 사회문제 해결에 관심 있는 국민이 4개 부문 중 하나...  briefing  \n",
       "10206  서양에 못지않게 일찍부터 법률체제를 구축한 중국은 주나라 대에 이르러서는 관리의 문...      edit  \n",
       "...                                                  ...       ...  \n",
       "7977   환경부는 2020 환경 데이터 활용 그린 뉴딜 아이디어 공모전 최종 경연 대회 및 ...  briefing  \n",
       "2494   코로나19 상황에서 다양한 형태의 긴급 돌봄을 제공하는 등 가정의 돌봄 부담을 완화...  briefing  \n",
       "30244  공공재개발을 통해서 사업 장애요인이 해소된다면 실수요자가 원하는 양질의 주택을 공급...    speech  \n",
       "35456  국립외교원과 유럽연합안보연구원이 공동으로 주최하는 한-EU 동북아 평화협력구상 세미...    speech  \n",
       "7816   환경부와 지자체는 대기오염물질 모니터링 및 오염원 특성 파악을 위해 11종의 측정망...  briefing  \n",
       "\n",
       "[40800 rows x 3 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(n=len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리 후, korean 컬럼에 한국어만을 담은 데이터를 저장\n",
    "- train: 145791\n",
    "- test: 48995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40799, 4)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train_df = preprocess_dataframe(train_df)\n",
    "preprocessed_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        노 국토교통부 장관은 서울역을 방문하여 방역실태를 점검했고 치밀한 시설물 점검 등을...\n",
       "1        경남 혁신도시에는 동남권 주태 건설 수요 및 지역내 중소기업 진흥을 감안해 한국토지...\n",
       "2        사례집엔 경북 성주군 별의별팀 전북 전주시 물왕멀 공동체 이야기 등이 간단하게 소개...\n",
       "3        사업 추진 과정에서 지정권자는 사전검토기구를 구성하여 용적률 등을 사전에 검토하고 ...\n",
       "4        공공택지에서 공급되는 공공분양주택은 분양가상한제가 적용되며 사전 청약 시행 단지 분...\n",
       "                               ...                        \n",
       "40795     전국기능경기대회는 심각한 코로나 상황으로 인해 방역에 특히 신경을 써서 추진하고자 한다\n",
       "40796    이륜차 사고예방 시범사업은 이동시간 논란이 많은 배달업 종사원들에 대해 안전 배달시...\n",
       "40797    강원도 철원군에서 2021년 통일로가요 결선 경연을 개최하며 결선에 진출한 12개 ...\n",
       "40798    국민권익위는 경기도 소재 21개 중고등학교를 표본으로 실태조사를 한 결과 저소득층 ...\n",
       "40799    국립중앙과학관은 국민이 직접 만든 영상 콘텐츠 국민들과 과학관이 함께 만드는 영상 ...\n",
       "Name: korean, Length: 40799, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train_df['korean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 데이터프레임을 datasets로 표현\n",
    "train_data = datasets.Dataset.from_pandas(preprocessed_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konlp의 Okt tokenizer를 사용\n",
    "kor_tokenizer = get_tokenizer(Komoran().pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['의','가','이','은', \n",
    "              '을','들','는','좀',\n",
    "              '잘','걍','과','도',\n",
    "              '를','으로','자','에',\n",
    "              '와','한','하다', '겠', \n",
    "              '음', '에', '에게', '다', '이다', \n",
    "              '됨', '데','내', '네', '게', '나', '하게', '중']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서 설정한 불용어를 제거하고, otk tokenizer를 사용하여 리뷰 데이터를 tokenize한다\n",
    "poses = [\"VA\", \"VV\", \"VCP\",\"VCN\", \"NNG\", \"NR\", \"MM\", \"IC\"]\n",
    "def kor_tokenize(review, tokenizer, max_length):\n",
    "    tokens = tokenizer(review[\"korean\"])\n",
    "    no_stop_words_tokens = [token[0] for token in tokens if (token[0] not in stop_words) and (len(token[0])>1)  and (token[1] in poses)]\n",
    "    no_stop_words_tokens = no_stop_words_tokens[:max_length]\n",
    "    length = len(no_stop_words_tokens)\n",
    "    return {\"tokens\": no_stop_words_tokens, \"length\": length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서 설정한 불용어를 제거하고, otk tokenizer를 사용하여 리뷰 데이터를 tokenize한다\n",
    "poses = [\"VA\", \"VV\", \"VCP\",\"VCN\", \"NNG\", \"NR\", \"MM\", \"IC\"]\n",
    "def ex_kor_tokenize(review, tokenizer, max_length):\n",
    "    tokens = tokenizer(review)\n",
    "    no_stop_words_tokens = [token[0] for token in tokens if (token[0] not in stop_words) and (len(token[0])>1)  and (token[1] in poses)]\n",
    "    no_stop_words_tokens = no_stop_words_tokens[:max_length]\n",
    "    length = len(no_stop_words_tokens)\n",
    "    return {\"tokens\": no_stop_words_tokens, \"length\": length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = preprocessed_train_df['korean'].apply(lambda x: ex_kor_tokenize(x, kor_tokenizer, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [tokens.iloc[index]['length'] for index in range(len(tokens))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.169219833819456"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40799/40799 [00:38<00:00, 1052.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "max_length=15\n",
    "train_data = train_data.map(\n",
    "    kor_tokenize, fn_kwargs={\"tokenizer\": kor_tokenizer, \"max_length\": max_length}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 40799/40799 [00:00<00:00, 51797.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 불용어만 존재하여 토큰이 없는 데이터를 삭제\n",
    "def filter_empty_tokens(example):\n",
    "    return len(example[\"tokens\"]) > 0\n",
    "\n",
    "train_data = train_data.filter(filter_empty_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터를 6:2:2로 나누어 학습 데이터, 검증 데이터로 분리\n",
    "test_size = 0.2\n",
    "train_test_data = train_data.train_test_split(test_size=test_size)\n",
    "train_data = train_test_data[\"train\"]\n",
    "test_data = train_test_data[\"test\"]\n",
    "valid_size=0.25\n",
    "train_valid_data = train_data.train_test_split(test_size=valid_size)\n",
    "train_data = train_valid_data[\"train\"]\n",
    "valid_data = train_valid_data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['보금자리', '금리', '시장', '불안', '생기', '조달', '방안', '방법', '시장', '안정', '위하', '노력']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <unk>, <pad> 특수 토큰을 추가한다\n",
    "special_tokens = [\"<unk>\", \"<pad>\"]\n",
    "min_freq = 3\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    train_data[\"tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_index = vocab[\"<unk>\"]\n",
    "pad_index = vocab[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(example, vocab):\n",
    "    ids = vocab.lookup_indices(example[\"tokens\"])\n",
    "    return {\"ids\": ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/24469 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 24469/24469 [00:03<00:00, 7724.40 examples/s]\n",
      "Map: 100%|██████████| 8157/8157 [00:00<00:00, 8233.72 examples/s]\n",
      "Map: 100%|██████████| 8157/8157 [00:01<00:00, 7413.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 리뷰 데이터들을 vocab에 존재하는 단어들로 mapping한다\n",
    "train_data = train_data.map(numericalize, fn_kwargs={\"vocab\": vocab})\n",
    "valid_data = valid_data.map(numericalize, fn_kwargs={\"vocab\": vocab})\n",
    "test_data = test_data.map(numericalize, fn_kwargs={\"vocab\": vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 torch 형태로 변환한다.\n",
    "train_data = train_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])\n",
    "valid_data = valid_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])\n",
    "test_data = test_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {label:index for index, label in enumerate(train_data.unique('label'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_ids = [i[\"ids\"] for i in batch]\n",
    "        batch_ids = nn.utils.rnn.pad_sequence(\n",
    "            batch_ids, padding_value=pad_index, batch_first=True\n",
    "        )\n",
    "        batch_length = [i[\"length\"] for i in batch]\n",
    "        batch_length = torch.stack(batch_length)\n",
    "        batch_label = [label_dict[i[\"label\"]] for i in batch]\n",
    "        batch_label = torch.tensor(batch_label, dtype=torch.long)\n",
    "        batch = {\"ids\": batch_ids, \"length\": batch_length, \"label\": batch_label}\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 데이터를 data_loader로 변환하여 모델에 실을 준비를 한다.\n",
    "batch_size = 512\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = GloVe()\n",
    "pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBoW(Neaural Bag of Words) 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7049, 6)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab), len(train_data.unique(\"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBoW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_index):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, ids):\n",
    "        # ids = [batch size, seq len]\n",
    "        embedded = self.embedding(ids)\n",
    "        # embedded = [batch size, seq len, embedding dim]\n",
    "        pooled = embedded.mean(dim=1)\n",
    "        # pooled = [batch size, embedding dim]\n",
    "        prediction = self.fc(pooled)\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 300\n",
    "output_dim = len(train_data.unique(\"label\"))\n",
    "\n",
    "NBoW_model = NBoW(vocab_size, embedding_dim, output_dim, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,116,506 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(NBoW_model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBoW_model.embedding.weight.data = pretrained_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "\n",
    "optimizer = optim.Adam(NBoW_model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cuda 사용함\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBoW_model = NBoW_model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NBoW(data_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    for batch in tqdm.tqdm(data_loader, desc=\"training...\"):\n",
    "        ids = batch[\"ids\"].to(device)\n",
    "        label = batch[\"label\"].to(device)\n",
    "        prediction = model(ids)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_NBoW(data_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(data_loader, desc=\"evaluating...\"):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            label = batch[\"label\"].to(device)\n",
    "            prediction = model(ids)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_NBoW(data_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(data_loader, desc=\"evaluating...\"):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            prediction = model(ids)\n",
    "            softmax_predictions = F.softmax(prediction, dim=1)\n",
    "            prediction = torch.argmax(softmax_predictions, dim=1)\n",
    "            preds+=prediction\n",
    "            # print(prediction)\n",
    "    preds = pd.Series([pred.item() for pred in preds])\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:01<00:00, 33.38it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 44.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train_loss: 1.759, train_acc: 0.350\n",
      "valid_loss: 1.686, valid_acc: 0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:01<00:00, 34.86it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 45.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "train_loss: 1.574, train_acc: 0.471\n",
      "valid_loss: 1.470, valid_acc: 0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:01<00:00, 27.86it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 43.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n",
      "train_loss: 1.388, train_acc: 0.495\n",
      "valid_loss: 1.345, valid_acc: 0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:01<00:00, 27.63it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 41.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n",
      "train_loss: 1.288, train_acc: 0.508\n",
      "valid_loss: 1.274, valid_acc: 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:01<00:00, 27.33it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 42.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n",
      "train_loss: 1.219, train_acc: 0.512\n",
      "valid_loss: 1.221, valid_acc: 0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:01<00:00, 27.51it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 42.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "train_loss: 1.162, train_acc: 0.527\n",
      "valid_loss: 1.178, valid_acc: 0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:01<00:00, 27.71it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 42.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n",
      "train_loss: 1.112, train_acc: 0.556\n",
      "valid_loss: 1.142, valid_acc: 0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:01<00:00, 25.54it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 42.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n",
      "train_loss: 1.065, train_acc: 0.583\n",
      "valid_loss: 1.109, valid_acc: 0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:01<00:00, 27.37it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 42.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n",
      "train_loss: 1.020, train_acc: 0.612\n",
      "valid_loss: 1.079, valid_acc: 0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:01<00:00, 27.54it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 41.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\n",
      "train_loss: 0.978, train_acc: 0.635\n",
      "valid_loss: 1.052, valid_acc: 0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "metrics = collections.defaultdict(list)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_acc = train_NBoW(\n",
    "        train_data_loader, NBoW_model, criterion, optimizer, device\n",
    "    )\n",
    "    valid_loss, valid_acc = evaluate_NBoW(valid_data_loader, NBoW_model, criterion, device)\n",
    "    metrics[\"train_losses\"].append(train_loss)\n",
    "    metrics[\"train_accs\"].append(train_acc)\n",
    "    metrics[\"valid_losses\"].append(valid_loss)\n",
    "    metrics[\"valid_accs\"].append(valid_acc)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(NBoW_model.state_dict(), \"base_nbow.pt\")\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    print(f\"train_loss: {train_loss:.3f}, train_acc: {train_acc:.3f}\")\n",
    "    print(f\"valid_loss: {valid_loss:.3f}, valid_acc: {valid_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8157, 8)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech': 0,\n",
       " 'paper': 1,\n",
       " 'public': 2,\n",
       " 'edit': 3,\n",
       " 'literature': 4,\n",
       " 'briefing': 5}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'speech',\n",
       " 1: 'paper',\n",
       " 2: 'public',\n",
       " 3: 'edit',\n",
       " 4: 'literature',\n",
       " 5: 'briefing'}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed_label_dict =  {value:key for key, value in label_dict.items()}\n",
    "reversed_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 32.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           speech\n",
      "1           speech\n",
      "2         briefing\n",
      "3           speech\n",
      "4         briefing\n",
      "           ...    \n",
      "8152    literature\n",
      "8153    literature\n",
      "8154        speech\n",
      "8155      briefing\n",
      "8156        speech\n",
      "Length: 8157, dtype: object\n"
     ]
    }
   ],
   "source": [
    "preds = predict_NBoW(test_data_loader, NBoW_model, criterion, device)\n",
    "preds = preds.map(reversed_label_dict)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source_data\\briefing\\REPORT-briefing-32676-000...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>source_data\\speech\\REPORT-speech-10748-00001.json</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source_data\\briefing\\REPORT-briefing-65558-000...</td>\n",
       "      <td>briefing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>source_data\\public\\REPORT-public-00080-00222.json</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>source_data\\briefing\\REPORT-briefing-33600-000...</td>\n",
       "      <td>briefing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path prediction\n",
       "0  source_data\\briefing\\REPORT-briefing-32676-000...     speech\n",
       "1  source_data\\speech\\REPORT-speech-10748-00001.json     speech\n",
       "2  source_data\\briefing\\REPORT-briefing-65558-000...   briefing\n",
       "3  source_data\\public\\REPORT-public-00080-00222.json     speech\n",
       "4  source_data\\briefing\\REPORT-briefing-33600-000...   briefing"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_df = pd.DataFrame({'path':test_data['path'], 'prediction':preds})\n",
    "expected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_df.to_csv(\"expected_df.tsv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM(RNN) 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        n_layers,\n",
    "        bidirectional,\n",
    "        dropout_rate,\n",
    "        pad_index,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            n_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_rate,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, ids, length):\n",
    "        # ids = [batch size, seq len]\n",
    "        # length = [batch size]\n",
    "        embedded = self.dropout(self.embedding(ids))\n",
    "        # embedded = [batch size, seq len, embedding dim]\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, length, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        output, output_length = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        # output = [batch size, seq len, hidden dim * n directions]\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n",
    "            # hidden = [batch size, hidden dim * 2]\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1])\n",
    "            # hidden = [batch size, hidden dim]\n",
    "        prediction = self.fc(hidden)\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 1000\n",
    "hidden_dim = 512\n",
    "output_dim = len(train_data.unique(\"label\"))\n",
    "n_layers = 4\n",
    "bidirectional = True\n",
    "dropout_rate = 0.2\n",
    "\n",
    "lstm_model = LSTM(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    hidden_dim,\n",
    "    output_dim,\n",
    "    n_layers,\n",
    "    bidirectional,\n",
    "    dropout_rate,\n",
    "    pad_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,742,354 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(lstm_model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif \"weight\" in name:\n",
    "                nn.init.orthogonal_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(7049, 300, padding_idx=1)\n",
       "  (lstm): LSTM(300, 128, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.embedding.weight.data = pretrained_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cuda 사용함\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = lstm_model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    for batch in tqdm.tqdm(dataloader, desc=\"training...\"):\n",
    "        ids = batch[\"ids\"].to(device)\n",
    "        length = batch[\"length\"]\n",
    "        label = batch[\"label\"].to(device)\n",
    "        prediction = model(ids, length)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(dataloader, desc=\"evaluating...\"):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            length = batch[\"length\"]\n",
    "            label = batch[\"label\"].to(device)\n",
    "            prediction = model(ids, length)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:03<00:00, 13.25it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 27.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train_loss: 1.485, train_acc: 0.423\n",
      "valid_loss: 1.242, valid_acc: 0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:03<00:00, 13.92it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 25.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "train_loss: 1.159, train_acc: 0.499\n",
      "valid_loss: 1.161, valid_acc: 0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:03<00:00, 13.54it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 26.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n",
      "train_loss: 1.047, train_acc: 0.540\n",
      "valid_loss: 1.120, valid_acc: 0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:03<00:00, 13.89it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 26.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n",
      "train_loss: 0.971, train_acc: 0.582\n",
      "valid_loss: 1.125, valid_acc: 0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:03<00:00, 13.57it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 26.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n",
      "train_loss: 0.932, train_acc: 0.608\n",
      "valid_loss: 1.145, valid_acc: 0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:03<00:00, 13.85it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 27.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "train_loss: 0.907, train_acc: 0.622\n",
      "valid_loss: 1.152, valid_acc: 0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:03<00:00, 13.70it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 26.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n",
      "train_loss: 0.877, train_acc: 0.641\n",
      "valid_loss: 1.181, valid_acc: 0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:03<00:00, 13.84it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 26.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n",
      "train_loss: 0.834, train_acc: 0.665\n",
      "valid_loss: 1.209, valid_acc: 0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:03<00:00, 13.92it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 26.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n",
      "train_loss: 0.790, train_acc: 0.687\n",
      "valid_loss: 1.247, valid_acc: 0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...: 100%|██████████| 48/48 [00:03<00:00, 13.55it/s]\n",
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 27.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\n",
      "train_loss: 0.747, train_acc: 0.711\n",
      "valid_loss: 1.304, valid_acc: 0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "metrics = collections.defaultdict(list)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_acc = train(\n",
    "        train_data_loader, lstm_model, criterion, optimizer, device\n",
    "    )\n",
    "    valid_loss, valid_acc = evaluate(valid_data_loader, lstm_model, criterion, device)\n",
    "    metrics[\"train_losses\"].append(train_loss)\n",
    "    metrics[\"train_accs\"].append(train_acc)\n",
    "    metrics[\"valid_losses\"].append(valid_loss)\n",
    "    metrics[\"valid_accs\"].append(valid_acc)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(lstm_model.state_dict(), \"base_lstm.pt\")\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    print(f\"train_loss: {train_loss:.3f}, train_acc: {train_acc:.3f}\")\n",
    "    print(f\"valid_loss: {valid_loss:.3f}, valid_acc: {valid_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating...: 100%|██████████| 16/16 [00:00<00:00, 27.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_, test_acc = evaluate(test_data_loader, lstm_model, criterion, device)\n",
    "print(f\"test_acc: {test_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
